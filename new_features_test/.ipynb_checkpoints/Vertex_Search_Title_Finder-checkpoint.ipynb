{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f4484dd",
   "metadata": {},
   "source": [
    "\n",
    "# 🔎 Vertex AI Search — Title Finder (Notebook)\n",
    "\n",
    "Minimalny, wygodny **notebook do wyszukiwania misji po przybliżonym tytule/haśle** w Vertex AI Search (Discovery Engine).  \n",
    "Bez Streamlita — same komórki + proste UI oparte o `ipywidgets`.\n",
    "\n",
    "**Co potrafi:**\n",
    "- Zapytanie tekstowe (nie musi być słowo w słowo), pobranie top‑K z Vertex Search.\n",
    "- (Opcjonalnie) lokalny **fuzzy re‑ranking** względem `display_id` / `mission_id` / `outcome` (RapidFuzz).\n",
    "- **Tabelka wyników** (`pandas.DataFrame`) + podgląd **surowego `struct_data` najlepszego trafienia**.\n",
    "- Opcjonalny **eksport do CSV/JSONL**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f327745b",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Zależności i autoryzacja\n",
    "\n",
    "Uruchom komórkę poniżej, jeśli nie masz pakietów:\n",
    "\n",
    "```bash\n",
    "%pip install -q google-cloud-discoveryengine rapidfuzz pandas ipywidgets\n",
    "```\n",
    "\n",
    "> **Autoryzacja**: ustaw poświadczenia, np. w terminalu JupyterLab:\n",
    "```bash\n",
    "export GOOGLE_APPLICATION_CREDENTIALS=/ścieżka/do/service-account.json\n",
    "```\n",
    "Albo w Pythonie (jednorazowo w tej sesji):\n",
    "```python\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/ścieżka/do/service-account.json\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56ce4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Jeśli trzeba, odkomentuj:\n",
    "# %pip install -q google-cloud-discoveryengine rapidfuzz pandas ipywidgets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9dc800",
   "metadata": {},
   "source": [
    "## 2) Importy i pomocnicze funkcje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adb1da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re, json, sys\n",
    "from typing import Any, Dict, List, Optional\n",
    "import pandas as pd\n",
    "\n",
    "# RapidFuzz (fuzzy match) — opcjonalny, ale zalecany\n",
    "try:\n",
    "    from rapidfuzz import fuzz\n",
    "    _FUZZY_OK = True\n",
    "except Exception:\n",
    "    _FUZZY_OK = False\n",
    "    def _simple_ratio(a: str, b: str) -> float:\n",
    "        a = (a or \"\").lower()\n",
    "        b = (b or \"\").lower()\n",
    "        if not a or not b:\n",
    "            return 0.0\n",
    "        if a in b or b in a:\n",
    "            return 100.0 * min(len(a), len(b)) / max(len(a), len(b))\n",
    "        return 0.0\n",
    "    class fuzz:  # fallback\n",
    "        @staticmethod\n",
    "        def partial_ratio(a, b): return _simple_ratio(a, b)\n",
    "        @staticmethod\n",
    "        def token_set_ratio(a, b): return _simple_ratio(a, b)\n",
    "\n",
    "# Google Discovery Engine client\n",
    "try:\n",
    "    from google.cloud import discoveryengine_v1 as de\n",
    "    from google.api_core.client_options import ClientOptions\n",
    "except Exception as e:\n",
    "    print(\"⚠️  Brak pakietu google-cloud-discoveryengine. Uruchom: %pip install google-cloud-discoveryengine\", file=sys.stderr)\n",
    "    raise\n",
    "\n",
    "def infer_api_endpoint(serving_config: str) -> str:\n",
    "    m = re.search(r\"/locations/([^/]+)/\", serving_config)\n",
    "    loc = m.group(1) if m else \"global\"\n",
    "    return f\"{loc}-discoveryengine.googleapis.com\"\n",
    "\n",
    "def search_vertex(\n",
    "    serving_config: str,\n",
    "    query: str,\n",
    "    page_size: int = 30,\n",
    "    api_endpoint: Optional[str] = None,\n",
    "    filter_expression: Optional[str] = None,\n",
    ") -> List[Dict[str, Any]]:\n",
    "    endpoint = api_endpoint or infer_api_endpoint(serving_config)\n",
    "    client = de.SearchServiceClient(client_options=ClientOptions(api_endpoint=endpoint))\n",
    "\n",
    "    req = de.SearchRequest(serving_config=serving_config, query=query, page_size=page_size)\n",
    "    # Włącz automatyczne rozszerzanie zapytań i korektę pisowni, jeśli dostępne\n",
    "    try:\n",
    "        req.query_expansion_spec = de.SearchRequest.QueryExpansionSpec(\n",
    "            condition=de.SearchRequest.QueryExpansionSpec.Condition.AUTO\n",
    "        )\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        req.spell_correction_spec = de.SearchRequest.SpellCorrectionSpec(\n",
    "            mode=de.SearchRequest.SpellCorrectionSpec.Mode.AUTO\n",
    "        )\n",
    "    except Exception:\n",
    "        pass\n",
    "    if filter_expression:\n",
    "        req.filter = filter_expression\n",
    "\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    for r in client.search(request=req):\n",
    "        doc = r.document\n",
    "        struct = dict(doc.struct_data) if doc.struct_data is not None else {}\n",
    "        links = struct.get(\"links\") if isinstance(struct.get(\"links\"), dict) else {}\n",
    "        tags = struct.get(\"tags\", [])\n",
    "        if isinstance(tags, dict):\n",
    "            tags = list(tags.values())\n",
    "        elif isinstance(tags, str):\n",
    "            tags = [tags]\n",
    "\n",
    "        rows.append({\n",
    "            \"doc_name\": doc.name,\n",
    "            \"doc_id\": getattr(doc, \"id\", None) or doc.name.split(\"/\")[-1],\n",
    "            \"engine_score\": getattr(r, \"score\", None),\n",
    "            \"mission_id\": struct.get(\"mission_id\"),\n",
    "            \"display_id\": struct.get(\"display_id\"),\n",
    "            \"mission_type\": struct.get(\"mission_type\"),\n",
    "            \"outcome\": struct.get(\"outcome\"),\n",
    "            \"tags\": tags,\n",
    "            \"approved\": struct.get(\"approved\"),\n",
    "            \"final_score\": struct.get(\"final_score\"),\n",
    "            \"lang\": struct.get(\"lang\"),\n",
    "            \"nodes_count\": struct.get(\"nodes_count\"),\n",
    "            \"edges_count\": struct.get(\"edges_count\"),\n",
    "            \"plan_uri\": links.get(\"plan_uri\"),\n",
    "            \"transcript_uri\": links.get(\"transcript_uri\"),\n",
    "            \"metrics_uri\": links.get(\"metrics_uri\"),\n",
    "            \"txt_uri\": links.get(\"txt_uri\"),\n",
    "            \"_struct\": struct,\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "def fuzzy_score(query: str, row: Dict[str, Any]) -> float:\n",
    "    fields = [row.get(\"display_id\") or \"\", row.get(\"mission_id\") or \"\", row.get(\"outcome\") or \"\"]\n",
    "    scores = [\n",
    "        fuzz.token_set_ratio(query, fields[0]),\n",
    "        fuzz.partial_ratio(query, fields[0]),\n",
    "        fuzz.token_set_ratio(query, fields[1]),\n",
    "        fuzz.partial_ratio(query, fields[1]),\n",
    "        fuzz.token_set_ratio(query, fields[2]),\n",
    "        fuzz.partial_ratio(query, fields[2]),\n",
    "    ]\n",
    "    return max(float(s or 0.0) for s in scores)\n",
    "\n",
    "def rerank_by_title(query: str, rows: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    for r in rows:\n",
    "        r[\"fuzzy_score\"] = fuzzy_score(query, r)\n",
    "        es = r.get(\"engine_score\") or 0.0\n",
    "        try:\n",
    "            es = float(es)\n",
    "        except Exception:\n",
    "            es = 0.0\n",
    "        r[\"combined_score\"] = (0.8 * r[\"fuzzy_score\"]) + (0.2 * es)\n",
    "    rows.sort(key=lambda x: (x.get(\"combined_score\", 0.0), x.get(\"engine_score\") or 0.0), reverse=True)\n",
    "    return rows\n",
    "\n",
    "def as_dataframe(rows: List[Dict[str, Any]]) -> pd.DataFrame:\n",
    "    cols = [\n",
    "        \"combined_score\", \"fuzzy_score\", \"engine_score\",\n",
    "        \"display_id\", \"mission_id\", \"mission_type\", \"outcome\",\n",
    "        \"tags\", \"approved\", \"final_score\", \"lang\",\n",
    "        \"nodes_count\", \"edges_count\",\n",
    "        \"plan_uri\", \"transcript_uri\", \"metrics_uri\"\n",
    "    ]\n",
    "    df = pd.DataFrame([{k: r.get(k) for k in cols} for r in rows])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aac44f",
   "metadata": {},
   "source": [
    "## 3) Proste UI (ipywidgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a7ebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import ipywidgets as W\n",
    "from IPython.display import display, JSON, clear_output\n",
    "\n",
    "serving_config_w = W.Text(\n",
    "    description=\"serving_config\",\n",
    "    placeholder=\"projects/PROJ/locations/eu/collections/default_collection/dataStores/DS/servingConfigs/default_config\",\n",
    "    layout=W.Layout(width=\"100%\")\n",
    ")\n",
    "api_endpoint_w = W.Text(\n",
    "    description=\"api_endpoint\",\n",
    "    placeholder=\"(auto from location)\",\n",
    "    layout=W.Layout(width=\"50%\")\n",
    ")\n",
    "query_w = W.Text(\n",
    "    description=\"query\",\n",
    "    value=\"fraud scoring pipeline rollback handling\",\n",
    "    layout=W.Layout(width=\"100%\")\n",
    ")\n",
    "topk_w = W.IntSlider(description=\"top_k\", min=1, max=100, step=1, value=30, continuous_update=False)\n",
    "filter_w = W.Text(description=\"filter\", placeholder='approved = true AND lang = \"pl\"', layout=W.Layout(width=\"100%\"))\n",
    "fuzzy_w = W.Checkbox(description=\"Fuzzy re‑rank\", value=True)\n",
    "search_btn = W.Button(description=\"🔎 Szukaj\", button_style=\"primary\")\n",
    "export_csv_w = W.Text(description=\"CSV\", placeholder=\"hits.csv\")\n",
    "export_json_w = W.Text(description=\"JSONL\", placeholder=\"hits.jsonl\")\n",
    "export_btn = W.Button(description=\"💾 Eksportuj\", button_style=\"\")\n",
    "\n",
    "hdr = W.HTML(\"<b>Parametry zapytania</b>\")\n",
    "box = W.VBox([hdr, serving_config_w, api_endpoint_w, query_w, topk_w, filter_w, W.HBox([fuzzy_w, search_btn])])\n",
    "display(box)\n",
    "\n",
    "out = W.Output()\n",
    "display(out)\n",
    "\n",
    "last_rows = []  # pamięć wyników w sesji\n",
    "\n",
    "def on_search(_):\n",
    "    global last_rows\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "        if not serving_config_w.value.strip():\n",
    "            print(\"❗ Podaj serving_config.\")\n",
    "            return\n",
    "        print(\"Zapytanie do Vertex Search...\")\n",
    "        try:\n",
    "            rows = search_vertex(\n",
    "                serving_config=serving_config_w.value.strip(),\n",
    "                query=query_w.value.strip(),\n",
    "                page_size=int(topk_w.value),\n",
    "                api_endpoint=api_endpoint_w.value.strip() or None,\n",
    "                filter_expression=filter_w.value.strip() or None,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(\"❌ Błąd wyszukiwania:\", e)\n",
    "            return\n",
    "        if not rows:\n",
    "            print(\"ℹ️ Brak wyników.\")\n",
    "            return\n",
    "        if fuzzy_w.value:\n",
    "            rows = rerank_by_title(query_w.value.strip(), rows)\n",
    "            print(f\"Uwaga: zastosowano fuzzy re‑ranking (RapidFuzz={_FUZZY_OK}).\")\n",
    "        last_rows = rows\n",
    "        df = as_dataframe(rows)\n",
    "        display(df)\n",
    "\n",
    "        # podgląd surowego struct_data najlepszego trafienia\n",
    "        print(\"\\n== Raw struct_data (best hit) ==\")\n",
    "        print(json.dumps(rows[0][\"_struct\"], ensure_ascii=False, indent=2))\n",
    "\n",
    "search_btn.on_click(on_search)\n",
    "\n",
    "# Eksport\n",
    "box2 = W.HBox([export_csv_w, export_json_w, export_btn])\n",
    "display(W.HTML(\"<b>Eksport wyników (opcjonalnie)</b>\"))\n",
    "display(box2)\n",
    "\n",
    "def on_export(_):\n",
    "    if not last_rows:\n",
    "        print(\"⚠️ Najpierw wyszukaj wyniki.\")\n",
    "        return\n",
    "    if export_csv_w.value.strip():\n",
    "        import csv\n",
    "        cols = [\n",
    "            \"combined_score\", \"fuzzy_score\", \"engine_score\",\n",
    "            \"display_id\", \"mission_id\", \"mission_type\", \"outcome\",\n",
    "            \"tags\", \"approved\", \"final_score\", \"lang\",\n",
    "            \"nodes_count\", \"edges_count\",\n",
    "            \"plan_uri\", \"transcript_uri\", \"metrics_uri\"\n",
    "        ]\n",
    "        with open(export_csv_w.value.strip(), \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            w = csv.DictWriter(f, fieldnames=cols)\n",
    "            w.writeheader()\n",
    "            for r in last_rows:\n",
    "                rec = {k: r.get(k) for k in cols}\n",
    "                for k, v in rec.items():\n",
    "                    if isinstance(v, (list, dict)):\n",
    "                        rec[k] = json.dumps(v, ensure_ascii=False)\n",
    "                w.writerow(rec)\n",
    "        print(f\"✅ CSV zapisany: {export_csv_w.value.strip()}\")\n",
    "    if export_json_w.value.strip():\n",
    "        with open(export_json_w.value.strip(), \"w\", encoding=\"utf-8\") as f:\n",
    "            for r in last_rows:\n",
    "                f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "        print(f\"✅ JSONL zapisany: {export_json_w.value.strip()}\")\n",
    "\n",
    "export_btn.on_click(on_export)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25ac994",
   "metadata": {},
   "source": [
    "## 4) Użycie programistyczne (bez widgetów)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e73b113",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Przykład „headless”:\n",
    "# serving_config = \"projects/PROJ/locations/eu/collections/default_collection/dataStores/DS/servingConfigs/default_config\"\n",
    "# rows = search_vertex(serving_config, query=\"your mission title\", page_size=30)\n",
    "# rows = rerank_by_title(\"your mission title\", rows)\n",
    "# pd.DataFrame(rows)[[\n",
    "#     \"combined_score\",\"fuzzy_score\",\"engine_score\",\"display_id\",\"mission_id\",\"plan_uri\"\n",
    "# ]].head(10)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
